{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b16ada7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CharacteristicGroup</th>\n",
       "      <th>CharacteristicValue</th>\n",
       "      <th>log_OR</th>\n",
       "      <th>p_value</th>\n",
       "      <th>N_category</th>\n",
       "      <th>N_worked_in_category</th>\n",
       "      <th>Percentage_worked_in_category</th>\n",
       "      <th>N_total_analysis</th>\n",
       "      <th>N_worked_total_analysis</th>\n",
       "      <th>Percentage_worked_total_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experience</td>\n",
       "      <td>Aucune expérience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2234</td>\n",
       "      <td>131</td>\n",
       "      <td>5.863921</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experience</td>\n",
       "      <td>Expérience &lt;1</td>\n",
       "      <td>-0.547586</td>\n",
       "      <td>5.981843e-07</td>\n",
       "      <td>7592</td>\n",
       "      <td>264</td>\n",
       "      <td>3.477345</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>experience</td>\n",
       "      <td>Expérience [1-5]</td>\n",
       "      <td>0.446012</td>\n",
       "      <td>2.041282e-06</td>\n",
       "      <td>17423</td>\n",
       "      <td>1545</td>\n",
       "      <td>8.867589</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>experience</td>\n",
       "      <td>Expérience [5-10]</td>\n",
       "      <td>0.649621</td>\n",
       "      <td>9.768420e-11</td>\n",
       "      <td>5330</td>\n",
       "      <td>568</td>\n",
       "      <td>10.656660</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experience</td>\n",
       "      <td>Expérience &gt;10</td>\n",
       "      <td>0.342657</td>\n",
       "      <td>9.772986e-04</td>\n",
       "      <td>5008</td>\n",
       "      <td>404</td>\n",
       "      <td>8.067093</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rate - User Has Min Wage</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>961</td>\n",
       "      <td>5</td>\n",
       "      <td>0.520291</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rate - User Has Min Wage</td>\n",
       "      <td>True</td>\n",
       "      <td>2.802380</td>\n",
       "      <td>4.260024e-10</td>\n",
       "      <td>36626</td>\n",
       "      <td>2907</td>\n",
       "      <td>7.936985</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rate - User Has 15 Plus</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30702</td>\n",
       "      <td>2058</td>\n",
       "      <td>6.703146</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rate - User Has 15 Plus</td>\n",
       "      <td>True</td>\n",
       "      <td>0.678472</td>\n",
       "      <td>7.805901e-56</td>\n",
       "      <td>6885</td>\n",
       "      <td>854</td>\n",
       "      <td>12.403776</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gender</td>\n",
       "      <td>Column not provided</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Codage Langues</td>\n",
       "      <td>NATIVE FRENCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23971</td>\n",
       "      <td>1438</td>\n",
       "      <td>5.998915</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Codage Langues</td>\n",
       "      <td>NON FRENCH</td>\n",
       "      <td>-0.094526</td>\n",
       "      <td>1.861400e-01</td>\n",
       "      <td>4410</td>\n",
       "      <td>242</td>\n",
       "      <td>5.487528</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Codage Langues</td>\n",
       "      <td>NON NATIVE FRENCH</td>\n",
       "      <td>0.884180</td>\n",
       "      <td>2.144351e-103</td>\n",
       "      <td>9206</td>\n",
       "      <td>1232</td>\n",
       "      <td>13.382577</td>\n",
       "      <td>37587</td>\n",
       "      <td>2912</td>\n",
       "      <td>7.747359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>City</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304</td>\n",
       "      <td>48</td>\n",
       "      <td>15.789474</td>\n",
       "      <td>3504</td>\n",
       "      <td>454</td>\n",
       "      <td>12.956621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>City</td>\n",
       "      <td>Paris</td>\n",
       "      <td>-0.254900</td>\n",
       "      <td>1.246819e-01</td>\n",
       "      <td>3200</td>\n",
       "      <td>406</td>\n",
       "      <td>12.687500</td>\n",
       "      <td>3504</td>\n",
       "      <td>454</td>\n",
       "      <td>12.956621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CharacteristicGroup  CharacteristicValue    log_OR        p_value  \\\n",
       "0                 experience    Aucune expérience       NaN            NaN   \n",
       "1                 experience        Expérience <1 -0.547586   5.981843e-07   \n",
       "2                 experience     Expérience [1-5]  0.446012   2.041282e-06   \n",
       "3                 experience    Expérience [5-10]  0.649621   9.768420e-11   \n",
       "4                 experience       Expérience >10  0.342657   9.772986e-04   \n",
       "5   Rate - User Has Min Wage                False       NaN            NaN   \n",
       "6   Rate - User Has Min Wage                 True  2.802380   4.260024e-10   \n",
       "7    Rate - User Has 15 Plus                False       NaN            NaN   \n",
       "8    Rate - User Has 15 Plus                 True  0.678472   7.805901e-56   \n",
       "9                     Gender  Column not provided       NaN            NaN   \n",
       "10            Codage Langues        NATIVE FRENCH       NaN            NaN   \n",
       "11            Codage Langues           NON FRENCH -0.094526   1.861400e-01   \n",
       "12            Codage Langues    NON NATIVE FRENCH  0.884180  2.144351e-103   \n",
       "13                      City             Bordeaux       NaN            NaN   \n",
       "14                      City                Paris -0.254900   1.246819e-01   \n",
       "\n",
       "    N_category  N_worked_in_category  Percentage_worked_in_category  \\\n",
       "0         2234                   131                       5.863921   \n",
       "1         7592                   264                       3.477345   \n",
       "2        17423                  1545                       8.867589   \n",
       "3         5330                   568                      10.656660   \n",
       "4         5008                   404                       8.067093   \n",
       "5          961                     5                       0.520291   \n",
       "6        36626                  2907                       7.936985   \n",
       "7        30702                  2058                       6.703146   \n",
       "8         6885                   854                      12.403776   \n",
       "9            0                     0                            NaN   \n",
       "10       23971                  1438                       5.998915   \n",
       "11        4410                   242                       5.487528   \n",
       "12        9206                  1232                      13.382577   \n",
       "13         304                    48                      15.789474   \n",
       "14        3200                   406                      12.687500   \n",
       "\n",
       "    N_total_analysis  N_worked_total_analysis  \\\n",
       "0              37587                     2912   \n",
       "1              37587                     2912   \n",
       "2              37587                     2912   \n",
       "3              37587                     2912   \n",
       "4              37587                     2912   \n",
       "5              37587                     2912   \n",
       "6              37587                     2912   \n",
       "7              37587                     2912   \n",
       "8              37587                     2912   \n",
       "9                  0                        0   \n",
       "10             37587                     2912   \n",
       "11             37587                     2912   \n",
       "12             37587                     2912   \n",
       "13              3504                      454   \n",
       "14              3504                      454   \n",
       "\n",
       "    Percentage_worked_total_analysis  \n",
       "0                           7.747359  \n",
       "1                           7.747359  \n",
       "2                           7.747359  \n",
       "3                           7.747359  \n",
       "4                           7.747359  \n",
       "5                           7.747359  \n",
       "6                           7.747359  \n",
       "7                           7.747359  \n",
       "8                           7.747359  \n",
       "9                                NaN  \n",
       "10                          7.747359  \n",
       "11                          7.747359  \n",
       "12                          7.747359  \n",
       "13                         12.956621  \n",
       "14                         12.956621  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prolog - Auto Generated #\n",
    "import os, uuid, matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot\n",
    "import pandas\n",
    "\n",
    "import sys\n",
    "sys.tracebacklimit = 0\n",
    "\n",
    "os.chdir(u'C:/Users/friha/PythonEditorWrapper_8de9bb44-c5e2-4b9b-a916-40b4add7c106')\n",
    "dataset = pandas.read_csv('input_df_889eb8aa-9cdf-4f54-8631-b9d8d6f007b3.csv')\n",
    "\n",
    "matplotlib.pyplot.figure(figsize=(5.55555555555556,4.16666666666667), dpi=72)\n",
    "matplotlib.pyplot.show = lambda args=None,kw=None: matplotlib.pyplot.savefig(str(uuid.uuid1()))\n",
    "# Original Script. Please update your script content here and once completed copy below section back to the original editing window #\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def sanitize_for_patsy(name):\n",
    "    if not isinstance(name, str): name = str(name)\n",
    "    name = re.sub(r'[^\\w_]', '_', name)\n",
    "    if name and name[0].isdigit(): name = 's_' + name\n",
    "    if not name: return \"sanitized_empty_val\"\n",
    "    return name\n",
    "\n",
    "def analyze_feature(df_input, outcome_col, original_feature_col_name,\n",
    "                    original_reference_category, # This is still needed to guide the model\n",
    "                    group_name_display,\n",
    "                    all_categories_ordered=None): # If None, categories are discovered dynamically\n",
    "    results = []\n",
    "    default_cols = {'log_OR': np.nan, 'p_value': np.nan,\n",
    "                    'N_category': 0, 'N_worked_in_category': 0,\n",
    "                    'N_total_analysis': 0, 'N_worked_total_analysis': 0,\n",
    "                    'Percentage_worked_in_category': np.nan,\n",
    "                    'Percentage_worked_total_analysis': np.nan}\n",
    "\n",
    "    if original_feature_col_name not in df_input.columns:\n",
    "        print(f\"Warning: Feature column '{original_feature_col_name}' not found. Skipping {group_name_display}.\")\n",
    "        results.append({'CharacteristicGroup': group_name_display,\n",
    "                        'CharacteristicValue': 'Feature column missing', **default_cols})\n",
    "        return results\n",
    "\n",
    "    df_feature = df_input[['user_id', outcome_col, original_feature_col_name]].copy()\n",
    "    df_feature[outcome_col] = pd.to_numeric(df_feature[outcome_col], errors='coerce')\n",
    "    # Convert feature to string EARLY to ensure consistent type for all operations\n",
    "    df_feature[original_feature_col_name] = df_feature[original_feature_col_name].astype(str)\n",
    "    df_feature.dropna(subset=[outcome_col, original_feature_col_name], inplace=True)\n",
    "    \n",
    "    if df_feature.empty:\n",
    "        print(f\"Info: No data for {group_name_display} after initial NaN drop for outcome/feature. Skipping model.\")\n",
    "        # If all_categories_ordered is None, we don't know what rows to create.\n",
    "        # If it's provided, we could create empty rows for them. For now, one error row.\n",
    "        error_char_value = 'No data after NaN drop'\n",
    "        if all_categories_ordered: # If an order was provided, list the first one\n",
    "            error_char_value = f\"No data for {all_categories_ordered[0]} (and others)\"\n",
    "        results.append({'CharacteristicGroup': group_name_display,\n",
    "                        'CharacteristicValue': error_char_value, **default_cols})\n",
    "        return results\n",
    "\n",
    "    try:\n",
    "        df_feature[outcome_col] = df_feature[outcome_col].astype(np.int64)\n",
    "    except Exception as e_astype:\n",
    "        print(f\"Error converting outcome '{outcome_col}' to np.int64 for {group_name_display}: {e_astype}. Skipping.\")\n",
    "        results.append({'CharacteristicGroup': group_name_display,\n",
    "                        'CharacteristicValue': f'Outcome conversion error: {e_astype}', **default_cols})\n",
    "        return results\n",
    "\n",
    "    df_feature.drop_duplicates(subset=['user_id', original_feature_col_name, outcome_col], inplace=True)\n",
    "\n",
    "    # Dynamic category discovery if all_categories_ordered is None\n",
    "    if all_categories_ordered is None:\n",
    "        # Discover unique categories from the data itself for this feature\n",
    "        # Ensure they are strings for consistent processing later\n",
    "        discovered_categories = sorted(df_feature[original_feature_col_name].unique().astype(str))\n",
    "        categories_to_iterate_for_output = discovered_categories\n",
    "        if not discovered_categories: # No categories found in data for this feature\n",
    "             print(f\"Info: No unique categories found in data for '{original_feature_col_name}' in group '{group_name_display}'.\")\n",
    "             results.append({'CharacteristicGroup': group_name_display,\n",
    "                             'CharacteristicValue': 'No categories in data', **default_cols})\n",
    "             return results\n",
    "    else: # Use provided order\n",
    "        categories_to_iterate_for_output = [str(cat) for cat in all_categories_ordered]\n",
    "\n",
    "\n",
    "    if original_feature_col_name == 'User Experience Group': # Or whatever your exact column name is\n",
    "        print(f\"DEBUG: Unique values for '{original_feature_col_name}' (group: {group_name_display}) being processed: {categories_to_iterate_for_output}\")\n",
    "        print(f\"DEBUG: Value counts in filtered df_feature for '{original_feature_col_name}':\\n{df_feature[original_feature_col_name].value_counts().head(10)}\")\n",
    "\n",
    "\n",
    "    sanitized_feature_col_name = sanitize_for_patsy(original_feature_col_name)\n",
    "    df_feature[sanitized_feature_col_name] = df_feature[original_feature_col_name].apply(sanitize_for_patsy)\n",
    "    sanitized_reference_category = sanitize_for_patsy(original_reference_category)\n",
    "\n",
    "\n",
    "    if df_feature.empty or df_feature[outcome_col].nunique() < 2 or df_feature[sanitized_feature_col_name].nunique() < 1 :\n",
    "        error_msg = 'Insufficient data or variance for modeling.'\n",
    "        # (More detailed error messages)\n",
    "        print(f\"Info: {error_msg} for {group_name_display}. Outputting counts only.\")\n",
    "        for orig_cat_val in categories_to_iterate_for_output: # Use the determined list\n",
    "            # (Count population logic - same as before)\n",
    "            N_cat = df_feature[df_feature[original_feature_col_name] == str(orig_cat_val)].shape[0]\n",
    "            N_worked_cat = df_feature[(df_feature[original_feature_col_name] == str(orig_cat_val)) & (df_feature[outcome_col] == 1)].shape[0]\n",
    "            perc_worked_cat = (N_worked_cat / N_cat * 100) if N_cat > 0 else np.nan\n",
    "            total_n_analysis = df_feature.shape[0]\n",
    "            total_worked_analysis = df_feature[outcome_col].sum() if total_n_analysis > 0 else 0\n",
    "            results.append({\n",
    "                'CharacteristicGroup': group_name_display, 'CharacteristicValue': str(orig_cat_val),\n",
    "                'log_OR': np.nan, 'p_value': np.nan,\n",
    "                'N_category': N_cat, 'N_worked_in_category': N_worked_cat,\n",
    "                'N_total_analysis': total_n_analysis, 'N_worked_total_analysis': total_worked_analysis,\n",
    "                'Percentage_worked_in_category': perc_worked_cat,\n",
    "                'Percentage_worked_total_analysis': (total_worked_analysis / total_n_analysis * 100) if total_n_analysis > 0 else np.nan\n",
    "            })\n",
    "        return results\n",
    "\n",
    "\n",
    "    actual_sanitized_categories_in_df = df_feature[sanitized_feature_col_name].unique()\n",
    "    current_sanitized_ref = sanitized_reference_category\n",
    "    if sanitized_reference_category not in actual_sanitized_categories_in_df:\n",
    "        # Fallback to mode if specified reference isn't in the (filtered) data for this analysis\n",
    "        if df_feature[original_feature_col_name].mode().shape[0] > 0:\n",
    "            mode_original_value = df_feature[original_feature_col_name].mode()[0]\n",
    "            current_sanitized_ref = sanitize_for_patsy(mode_original_value)\n",
    "            print(f\"Warning: Sanitized reference '{sanitized_reference_category}' (from original '{original_reference_category}') not found for '{group_name_display}'. Using most frequent original value '{mode_original_value}' (sanitized: '{current_sanitized_ref}').\")\n",
    "            if current_sanitized_ref not in actual_sanitized_categories_in_df: # Should not happen if mode is from df_feature\n",
    "                 print(f\"CRITICAL WARNING: Mode '{mode_original_value}' (sanitized: '{current_sanitized_ref}') also not in sanitized categories. Model will likely fail for {group_name_display}\")\n",
    "        else: # No mode means df_feature is effectively empty for this column\n",
    "            print(f\"CRITICAL: No mode available for reference for {group_name_display}. Cannot fit model reliably.\")\n",
    "            # (Fallback to counts for categories_to_iterate_for_output)\n",
    "            for orig_cat_val in categories_to_iterate_for_output:\n",
    "                results.append({'CharacteristicGroup': group_name_display, 'CharacteristicValue': str(orig_cat_val), **default_cols, 'N_total_analysis': df_feature.shape[0]})\n",
    "            return results\n",
    "    sanitized_reference_category = current_sanitized_ref # Use the validated or mode-based reference\n",
    "\n",
    "    if df_feature[sanitized_feature_col_name].nunique() < 2: # Only one unique predictor category\n",
    "        print(f\"Info: Only one unique predictor category ('{df_feature[original_feature_col_name].unique()[0]}') for {group_name_display}. Outputting counts only.\")\n",
    "        # (Fallback to counts - same as before, but iterate categories_to_iterate_for_output)\n",
    "        for orig_cat_val in categories_to_iterate_for_output:\n",
    "            N_cat = df_feature[df_feature[original_feature_col_name] == str(orig_cat_val)].shape[0]\n",
    "            # ... (rest of count logic)\n",
    "            N_worked_cat = df_feature[(df_feature[original_feature_col_name] == str(orig_cat_val)) & (df_feature[outcome_col] == 1)].shape[0]\n",
    "            perc_worked_cat = (N_worked_cat / N_cat * 100) if N_cat > 0 else np.nan\n",
    "            total_n_analysis = df_feature.shape[0]\n",
    "            total_worked_analysis = df_feature[outcome_col].sum() if total_n_analysis > 0 else 0\n",
    "            results.append({\n",
    "                'CharacteristicGroup': group_name_display, 'CharacteristicValue': str(orig_cat_val),\n",
    "                'log_OR': np.nan, 'p_value': np.nan,\n",
    "                'N_category': N_cat, 'N_worked_in_category': N_worked_cat,\n",
    "                'N_total_analysis': total_n_analysis, 'N_worked_total_analysis': total_worked_analysis,\n",
    "                'Percentage_worked_in_category': perc_worked_cat,\n",
    "                'Percentage_worked_total_analysis': (total_worked_analysis / total_n_analysis * 100) if total_n_analysis > 0 else np.nan\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    formula = f\"{outcome_col} ~ C({sanitized_feature_col_name}, Treatment(reference='{sanitized_reference_category}'))\"\n",
    "    print(f\"Attempting to fit model for {group_name_display} with formula: {formula}\")\n",
    "    try:\n",
    "        model = smf.logit(formula, data=df_feature).fit(disp=0)\n",
    "        log_odds = model.params\n",
    "        p_values = model.pvalues\n",
    "        # Successful fit\n",
    "        for orig_cat_val_iter in categories_to_iterate_for_output: # Iterate using determined list\n",
    "            # (Populate results for successful fit - same as before)\n",
    "            str_orig_cat_val = str(orig_cat_val_iter) # Ensure it's string for comparison and dict key\n",
    "            sanitized_cat_val_iter = sanitize_for_patsy(str_orig_cat_val)\n",
    "            N_cat = df_feature[df_feature[original_feature_col_name] == str_orig_cat_val].shape[0]\n",
    "            N_worked_cat = df_feature[(df_feature[original_feature_col_name] == str_orig_cat_val) & (df_feature[outcome_col] == 1)].shape[0]\n",
    "            perc_worked_cat = (N_worked_cat / N_cat * 100) if N_cat > 0 else np.nan\n",
    "            total_n_analysis = df_feature.shape[0]\n",
    "            total_worked_analysis = df_feature[outcome_col].sum()\n",
    "\n",
    "            current_log_or_val, current_p_value_val = np.nan, np.nan\n",
    "            if sanitized_cat_val_iter == sanitized_reference_category:\n",
    "                pass # Keep as NaN for reference\n",
    "            else:\n",
    "                param_name = f\"C({sanitized_feature_col_name}, Treatment(reference='{sanitized_reference_category}'))[T.{sanitized_cat_val_iter}]\"\n",
    "                current_log_or_val = log_odds.get(param_name, np.nan)\n",
    "                current_p_value_val = p_values.get(param_name, np.nan)\n",
    "            \n",
    "            results.append({\n",
    "                'CharacteristicGroup': group_name_display, 'CharacteristicValue': str_orig_cat_val,\n",
    "                'log_OR': current_log_or_val, 'p_value': current_p_value_val,\n",
    "                'N_category': N_cat, 'N_worked_in_category': N_worked_cat,\n",
    "                'N_total_analysis': total_n_analysis, 'N_worked_total_analysis': total_worked_analysis,\n",
    "                'Percentage_worked_in_category': perc_worked_cat,\n",
    "                'Percentage_worked_total_analysis': (total_worked_analysis / total_n_analysis * 100) if total_n_analysis > 0 else np.nan\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting model or processing results for {group_name_display} (feature: {original_feature_col_name}): {e}. Outputting counts only.\")\n",
    "        # Fallback to counts for ALL categories of this group if model fails\n",
    "        for orig_cat_val in categories_to_iterate_for_output: # Iterate using determined list\n",
    "            # (Count population logic - same as before)\n",
    "            N_cat = df_feature[df_feature[original_feature_col_name] == str(orig_cat_val)].shape[0]\n",
    "            N_worked_cat = df_feature[(df_feature[original_feature_col_name] == str(orig_cat_val)) & (df_feature[outcome_col] == 1)].shape[0]\n",
    "            perc_worked_cat = (N_worked_cat / N_cat * 100) if N_cat > 0 else np.nan\n",
    "            total_n_analysis = df_feature.shape[0]\n",
    "            total_worked_analysis = df_feature[outcome_col].sum() if total_n_analysis > 0 else 0\n",
    "            results.append({\n",
    "                'CharacteristicGroup': group_name_display, 'CharacteristicValue': str(orig_cat_val),\n",
    "                'log_OR': np.nan, 'p_value': np.nan,\n",
    "                'N_category': N_cat, 'N_worked_in_category': N_worked_cat,\n",
    "                'N_total_analysis': total_n_analysis, 'N_worked_total_analysis': total_worked_analysis,\n",
    "                'Percentage_worked_in_category': perc_worked_cat,\n",
    "                'Percentage_worked_total_analysis': (total_worked_analysis / total_n_analysis * 100) if total_n_analysis > 0 else np.nan\n",
    "            })\n",
    "    return results\n",
    "\n",
    "\n",
    "# --- Main Script ---\n",
    "all_results_list = []\n",
    "outcome_variable_name = 'UserHasWorked'\n",
    "\n",
    "# Define default columns for error/fallback rows to ensure consistent DataFrame structure\n",
    "default_error_row_values = {\n",
    "    'log_OR': np.nan, 'p_value': np.nan,\n",
    "    'N_category': 0, 'N_worked_in_category': 0,\n",
    "    'N_total_analysis': 0, 'N_worked_total_analysis': 0,\n",
    "    'Percentage_worked_in_category': np.nan,\n",
    "    'Percentage_worked_total_analysis': np.nan\n",
    "}\n",
    "\n",
    "if 'user_id' not in dataset.columns or outcome_variable_name not in dataset.columns:\n",
    "    output_df = pd.DataFrame([{\n",
    "        'CharacteristicGroup': 'Error',\n",
    "        'CharacteristicValue': f\"'user_id' or '{outcome_variable_name}' missing.\",\n",
    "        **default_error_row_values\n",
    "    }])\n",
    "else:\n",
    "    dataset[outcome_variable_name] = pd.to_numeric(dataset[outcome_variable_name], errors='coerce')\n",
    "    dataset.dropna(subset=[outcome_variable_name], inplace=True)\n",
    "    try:\n",
    "        dataset[outcome_variable_name] = dataset[outcome_variable_name].astype(np.int64)\n",
    "    except Exception as e_main_astype:\n",
    "        print(f\"CRITICAL ERROR in Main Script: Could not convert outcome variable '{outcome_variable_name}' to np.int64. Error: {e_main_astype}\")\n",
    "        output_df = pd.DataFrame([{\n",
    "            'CharacteristicGroup': 'Error',\n",
    "            'CharacteristicValue': f\"Failed to process outcome variable '{outcome_variable_name}'.\",\n",
    "            **default_error_row_values\n",
    "        }])\n",
    "        # If this critical error happens, output_df is set, and the script will likely end here\n",
    "        # or the final output_df check will use this one.\n",
    "\n",
    "\n",
    "    # Only proceed if output_df wasn't set by a critical error above\n",
    "    if 'output_df' not in locals():\n",
    "        # 1. Experience Analysis - DYNAMIC LOADING\n",
    "        experience_reference_category = 'Aucune expérience'\n",
    "        all_results_list.extend(analyze_feature(dataset, outcome_variable_name, 'User Experience Group',\n",
    "                                           original_reference_category=experience_reference_category,\n",
    "                                           group_name_display='experience',\n",
    "                                           all_categories_ordered=None))\n",
    "\n",
    "        # 2. Rate Analysis\n",
    "        all_results_list.extend(analyze_feature(dataset, outcome_variable_name, 'User Has Min Wage Rate',\n",
    "                                           original_reference_category=False,\n",
    "                                           group_name_display='Rate - User Has Min Wage',\n",
    "                                           all_categories_ordered=None))\n",
    "        all_results_list.extend(analyze_feature(dataset, outcome_variable_name, 'User Has 15 Plus Rate',\n",
    "                                           original_reference_category=False,\n",
    "                                           group_name_display='Rate - User Has 15 Plus',\n",
    "                                           all_categories_ordered=None))\n",
    "\n",
    "        # 3. Gender Analysis\n",
    "        if 'User_Gender' in dataset.columns:\n",
    "            gender_reference_category = 'F'\n",
    "            all_results_list.extend(analyze_feature(dataset, outcome_variable_name, 'User_Gender',\n",
    "                                               original_reference_category=gender_reference_category,\n",
    "                                               group_name_display='Gender',\n",
    "                                               all_categories_ordered=None))\n",
    "        else:\n",
    "            print(\"Info: 'User_Gender' column not found. Skipping.\")\n",
    "            all_results_list.append({\n",
    "                'CharacteristicGroup': 'Gender',\n",
    "                'CharacteristicValue': 'Column not provided',\n",
    "                **default_error_row_values\n",
    "            })\n",
    "\n",
    "        # 4. Language Analysis\n",
    "        language_reference = 'NATIVE FRENCH'\n",
    "        all_results_list.extend(analyze_feature(dataset, outcome_variable_name, 'User French Proficiency',\n",
    "                                           original_reference_category=language_reference,\n",
    "                                           group_name_display='Codage Langues',\n",
    "                                           all_categories_ordered=None))\n",
    "\n",
    "        # 5. City Analysis\n",
    "        if 'User Is In Paris' in dataset.columns and 'User Is In Bordeaux' in dataset.columns:\n",
    "            temp_df_city = dataset[['user_id', outcome_variable_name, 'User Is In Paris', 'User Is In Bordeaux']].copy()\n",
    "            def assign_city_group(row):\n",
    "                is_paris = False\n",
    "                if pd.notna(row['User Is In Paris']):\n",
    "                    if isinstance(row['User Is In Paris'], (bool, np.bool_)): is_paris = row['User Is In Paris']\n",
    "                    elif isinstance(row['User Is In Paris'], (int, float)): is_paris = bool(row['User Is In Paris'])\n",
    "                    elif isinstance(row['User Is In Paris'], str): is_paris = row['User Is In Paris'].lower() == 'true'\n",
    "                is_bordeaux = False\n",
    "                if pd.notna(row['User Is In Bordeaux']):\n",
    "                    if isinstance(row['User Is In Bordeaux'], (bool, np.bool_)): is_bordeaux = row['User Is In Bordeaux']\n",
    "                    elif isinstance(row['User Is In Bordeaux'], (int, float)): is_bordeaux = bool(row['User Is In Bordeaux'])\n",
    "                    elif isinstance(row['User Is In Bordeaux'], str): is_bordeaux = row['User Is In Bordeaux'].lower() == 'true'\n",
    "                if is_paris: return 'Paris'\n",
    "                if is_bordeaux: return 'Bordeaux'\n",
    "                return 'Other'\n",
    "            temp_df_city['City_Group_Temp'] = temp_df_city.apply(assign_city_group, axis=1)\n",
    "            df_paris_bordeaux = temp_df_city[temp_df_city['City_Group_Temp'].isin(['Paris', 'Bordeaux'])].copy()\n",
    "\n",
    "            if not df_paris_bordeaux.empty and df_paris_bordeaux[outcome_variable_name].notna().all():\n",
    "                 all_results_list.extend(analyze_feature(df_paris_bordeaux, outcome_variable_name, 'City_Group_Temp',\n",
    "                                               original_reference_category='Bordeaux',\n",
    "                                               group_name_display='City',\n",
    "                                               all_categories_ordered=['Bordeaux', 'Paris']))\n",
    "            else:\n",
    "                print(\"Info: Not enough data for Paris/Bordeaux for City analysis or outcome variable has issues.\")\n",
    "                all_results_list.append({\n",
    "                    'CharacteristicGroup': 'City',\n",
    "                    'CharacteristicValue': 'Paris/Bordeaux No Valid Data',\n",
    "                    **default_error_row_values\n",
    "                })\n",
    "        else:\n",
    "            print(\"Info: City columns ('User Is In Paris', 'User Is In Bordeaux') not found.\")\n",
    "            all_results_list.append({\n",
    "                'CharacteristicGroup': 'City',\n",
    "                'CharacteristicValue': 'Columns not provided',\n",
    "                **default_error_row_values\n",
    "            })\n",
    "\n",
    "        # Final DataFrame creation\n",
    "        if all_results_list:\n",
    "            output_df = pd.DataFrame(all_results_list)\n",
    "            cols_order = ['CharacteristicGroup', 'CharacteristicValue', 'log_OR', 'p_value',\n",
    "                          'N_category', 'N_worked_in_category', 'Percentage_worked_in_category',\n",
    "                          'N_total_analysis', 'N_worked_total_analysis', 'Percentage_worked_total_analysis']\n",
    "            output_df = output_df[[col for col in cols_order if col in output_df.columns]]\n",
    "        elif 'output_df' not in locals(): # If no critical error set output_df and list is empty\n",
    "            output_df = pd.DataFrame([{\n",
    "                'CharacteristicGroup': 'Error',\n",
    "                'CharacteristicValue': 'No results generated and no critical error caught.',\n",
    "                **default_error_row_values\n",
    "            }])\n",
    "\n",
    "# If output_df was not defined at all (e.g. first check passed but then main_astype failed AND\n",
    "# the 'output_df' not in locals() check for all_results_list also didn't catch it because an error occurred\n",
    "# before all_results_list was processed), create a fallback. This is a safeguard.\n",
    "if 'output_df' not in locals():\n",
    "    output_df = pd.DataFrame([{\n",
    "        'CharacteristicGroup': 'Critical Script Failure',\n",
    "        'CharacteristicValue': 'output_df was not created. Check logs for earlier errors.',\n",
    "        **default_error_row_values\n",
    "    }])\n",
    "\n",
    "output_df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
